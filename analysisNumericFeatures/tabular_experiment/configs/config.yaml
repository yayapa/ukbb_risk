experiment:
  name: "results_val"
  description: "trying to improve fusion"
random_seed: [1514, 0, 42, 867228, 29847]
mode: "val"
remove_categories:
  - "nothing"
  - "urinary_bladder"
  - "prostate"

#cross_validation:
optimization:
  #n_folds: 10
  n_trials: 500
  timeout: 900

paths:
  results: "put_yours/results"
  datasets: "put_yours"

datasets:
  - "cvd2_3m_3y"
  - "pancreas_3m_3y"
  - "liver_3m_3y"
  - "cancer_3m_3y"
  - "copd_3m_3y"
  - "ckd_3m_3y"
  - "osteoarthritis_3m_3y"

feature_pools:
  non_image+total_segmentator:
    - "put_yours"

models:
  MLP:
    type: "sklearn.neural_network.MLPClassifier"
    parameters:
      hidden_layer_sizes:
        - [ 64 ]           # Single layer with 64 units
        - [ 32 ]           # Single layer with 32 units
        - [ 64, 32 ]       # Two layers: 64 and 32 units
        - [ 64, 64 ]       # Two layers with 64 units each
        - [ 128, 128 ]     # Two layers with 128 units each
        - [ 128, 64, 32 ]  # Three layers: 128, 64, and 32 units
        - [ 256, 128, 64 ]
        - [ 512, 128 ]
        - [ 256, 256 ]
        - [128, 512]
      learning_rate_init: [1e-6, 1e-2 ]
      alpha: [0.1, 2.0]
      batch_size: [64, 256]
      activation: "relu"
      early_stopping: true
      validation_fraction: 0.1
      n_iter_no_change: 10
      solver: "adam"
      max_iter: 10000
  RF:
    type: "sklearn.ensemble.RandomForestClassifier"
    parameters:
      n_estimators: [50, 200]
      max_depth: [3, 15]
      min_samples_split: [5, 30]
      min_samples_leaf: [5, 20]
      criterion: ["gini", "entropy", "log_loss"]
      max_features: ["sqrt", "log2"]
      class_weight: "balanced"
      bootstrap: true
      oob_score: true

  XGB:
    type: "xgboost.XGBClassifier"
    parameters:
      max_depth: [3, 15]
      min_child_weight: [3, 10]
      gamma: [1e-2, 5.0]
      subsample: [0.6, 0.95]
      colsample_bytree: [0.6, 0.95]
      learning_rate: [1e-4, 1e-1]
      n_estimators: [50, 300]
      reg_alpha: [1e-2, 5.0]
      reg_lambda: [1e-2, 5.0]
      objective: "binary:logistic"
      eval_metric: "logloss"
      tree_method: "exact"
      booster: ["gbtree", "dart"]
      #tree_method: "hist"

