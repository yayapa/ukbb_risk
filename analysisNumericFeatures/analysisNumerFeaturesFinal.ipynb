{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')  # Adjust the path accordingly\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from DataAnalysis.EventAnalyzer import EventAnalyzer\n",
    "import pandas as pd\n",
    "from PrepareDataset.DataEncoder.FeatureCollector import FeatureCollector\n",
    "\n",
    "from PrepareDataset.DataEncoder.PreprocessLogger import PreprocessLogger\n",
    "\n",
    "logger = PreprocessLogger(PreprocessLogger.__name__, jupyter=False, file_name=\"liver.log\").logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## bca data\n",
    "PROJECT_PATH = \"/home/dmitrii/GitHub/ukbb_risk_assessment/\"\n",
    "cohort_path = PROJECT_PATH + 'PrepareDataset/resources/3m_3y/pancreas_3m_3y/'\n",
    "data_showcase_path = (PROJECT_PATH + 'PrepareDataset/resources/Data_Dictionary_Showcase.csv')\n",
    "\n",
    "eids_path = cohort_path +'labels.csv'\n",
    "eids_to_read = pd.read_csv(eids_path)['eid'].tolist()\n",
    "cardiac_radiomics_path = PROJECT_PATH + \"PrepareDataset/resources/cardiac_features/table_all.csv\"\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b81547363c707e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(eids_to_read)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da2b2f91a20e8e06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_collector = FeatureCollector(label_path=(cohort_path + \"labels_with_val.csv\"), logger=logger)\n",
    "file_path_to_features = cohort_path + \"/preprocessed_features/\"\n",
    "#file_path_to_features = cohort_path + \"/encoded_features/\"\n",
    "feature_collector.load_features(data_showcase_path=data_showcase_path, file_path_to_features=file_path_to_features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1bd8b5392a81f0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set_of_features= set([\n",
    "    #\"cardiac_radiomics\",\n",
    "    #\"bca_norm\", \n",
    "    #\"elixhauser_comorbidities\", \n",
    "    #\"basic_features\", \n",
    "    #\"met_physical_activity\", \n",
    "    #\"smoking\", \n",
    "    #\"alcohol\", \n",
    "    #\"general_health\", \n",
    "    #\"diet\", \n",
    "    #\"clinical_biomarkers\"\n",
    "    #\"total_radiomics\",\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca44ec2e017f5a28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(cohort_path + \"labels_with_val.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f71525cf43f587a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_labels['split'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bb2845220acc2bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = feature_collector.get_features(set_of_features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf28d6f16e86b2d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(features.columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32f5105e24bdb663"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features[\"split\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42143a2e27225017"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# replace split column in features_ckd with df_labels split column merging by eid\n",
    "features.drop(columns=[\"split\"], inplace=True)\n",
    "features = features.merge(df_labels[[\"eid\", \"split\"]], on=\"eid\", how=\"left\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b37c4d04e7496392"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "32f844ba79d3e470"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features[\"split\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b27ec0f363412cca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features.drop(columns=[\"event\", \"time_to_event\", \"split\"], inplace=True)\n",
    "#features.to_csv(\"/home/dmitrii/GitHub/ukbb_risk_assessment/PrepareDataset/resources/3m_3y/cvd2_3m_3y/tabular_final_preprocessed/bca+cardiac.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d3017a16860ed45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"/home/dmitrii/GitHub/ukbb_risk_assessment/data/projects/risk_assessment/labels/3m_3y/cvd2_3m_3y/tabular_final_preprocessed/bca+cardiac+nonimage_tabular.csv\")\n",
    "len(features.columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b161d5d8bcc9352"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61d7fbcd254ee6f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ca = EventAnalyzer(features, logger=logger)\n",
    "ca.remove_one_value_columns()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c557c0df41f78d85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr_table = ca.get_correlated_with_target(threshold=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ff7960628916e46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(corr_table)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc67c95cb70fa59f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e057a28b7acf51a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ca.data.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e004b8ceacb56498"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ca.data.drop(columns=[\"10P Liver PDFF (proton density fat fraction)\", 'FR liver PDFF mean', 'Total lean tissue volume', 'Total thigh fat-free muscle volume'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ef79c75a3eaeb5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ca.split_data()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f74ba097817f1f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _visualize_results(results):\n",
    "    df = pd.DataFrame({\n",
    "    model: {\n",
    "        metric: f\"{values['mean']:.3f} ± {values['std']:.3f}\"\n",
    "        for metric, values in metrics.items()\n",
    "    }\n",
    "    for model, metrics in results.items()\n",
    "    }).T\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "150acfe97dcf1ef5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import autogluon.tabular as ag\n",
    "\n",
    "from autogluon.common import space\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score\n",
    "from itertools import product\n",
    "from autogluon.common import space\n",
    "\n",
    "\n",
    "def train_and_evaluate(ca):\n",
    "    seeds = ca.RANDOM_SET_SEED[:5]\n",
    "    \n",
    "    # Prepare the training and test datasets\n",
    "    train_data = ca.data[ca.data['split'] == 'train'].drop(columns=['split', 'eid', 'event', 'time_to_event']).copy()\n",
    "    train_data['label'] = ca.data[ca.data['split'] == 'train']['event'].copy()\n",
    "    test_data = ca.data[ca.data['split'] == 'test'].drop(columns=['split', 'eid', 'event', 'time_to_event']).copy()\n",
    "    test_data['label'] = ca.data[ca.data['split'] == 'test']['event'].copy()\n",
    "    val_data = ca.data[ca.data['split'] == 'val'].drop(columns=['split', 'eid', 'event', 'time_to_event']).copy()\n",
    "    val_data['label'] = ca.data[ca.data['split'] == 'val']['event'].copy()\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    models_to_train = ['RF', 'XGB', 'NN_TORCH'] #['XT', 'RF', 'XGB', 'NN_TORCH', 'CAT', 'GBM']\n",
    "\n",
    "    \n",
    "    for model in models_to_train:\n",
    "        results[model] = {'accuracy': [], 'balanced_accuracy': [], 'f1': [], 'roc_auc': [], 'feature_importances': {\"test\":[], \"test_val\": []}}\n",
    "        for seed in seeds:\n",
    "\n",
    "            predictor = ag.TabularPredictor(label='label', eval_metric='balanced_accuracy', path=f'./autogluon/model_{model}_seed_{seed}', verbosity=2, problem_type='binary')\n",
    "            hyperparameters = {\n",
    "                'RF': {\n",
    "                    'RF': {\n",
    "                        'random_state': seed,  # Use your seed here\n",
    "                    }\n",
    "                },  \n",
    "                'XGB': {\n",
    "                    'XGB': {\n",
    "                        'random_state': seed,\n",
    "                        'subsample': 0.98,\n",
    "                        'colsample_bytree': 0.98,\n",
    "                    }\n",
    "                },\n",
    "                'NN_TORCH': {\n",
    "                    'NN_TORCH': {\n",
    "                        \"seed_value\":seed,\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            predictor.fit(\n",
    "                train_data=train_data,\n",
    "                tuning_data=val_data,  # Set validation data for hyperparameter tuning\n",
    "                hyperparameters=hyperparameters[model],\n",
    "                time_limit=600,   # Time limit per seed (10 minutes)\n",
    "                num_bag_folds=0,  # No bagging\n",
    "                num_stack_levels=0,  # No stacking\n",
    "                presets='best_quality',  # Best quality preset\n",
    "            )\n",
    "            \n",
    "            y_pred = predictor.predict(test_data)\n",
    "            y_proba = predictor.predict_proba(test_data)\n",
    "            y_proba = y_proba.to_numpy()[:, 1]\n",
    "            metrics = {\n",
    "                \"accuracy\": accuracy_score(test_data['label'], y_pred),\n",
    "                \"balanced_accuracy\": balanced_accuracy_score(test_data['label'], y_pred),\n",
    "                \"f1\": f1_score(test_data['label'], y_pred),\n",
    "                \"roc_auc\": roc_auc_score(test_data['label'], y_proba),\n",
    "            }\n",
    "    \n",
    "            # Store the metrics for this model and seed\n",
    "            for metric in metrics:\n",
    "                results[model][metric].append(metrics[metric])\n",
    "            test_val_data = pd.concat([test_data, val_data])\n",
    "            results[model]['feature_importances'][\"test\"].append(predictor.feature_importance(data=test_data, num_shuffle_sets=5))\n",
    "            results[model]['feature_importances'][\"test_val\"].append(predictor.feature_importance(data=test_val_data, num_shuffle_sets=5))\n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "        \n",
    "    # Calculate mean and standard deviation across seeds for each model\n",
    "    results_combined = {}\n",
    "    for model_name in results:\n",
    "        results_combined[model_name] = {}\n",
    "        for metric in results[model_name]:\n",
    "            if metric != 'feature_importances':\n",
    "                results_combined[model_name][metric] = {\n",
    "                    \"mean\": np.mean(results[model_name][metric]),\n",
    "                    \"std\": np.std(results[model_name][metric])\n",
    "                }\n",
    "            else:\n",
    "                results_combined[model_name][metric] = results[model_name][metric]\n",
    "    \n",
    "    return results_combined#, best_model_predictor\n",
    "\n",
    "\n",
    "results = train_and_evaluate(ca)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56de01bb7849dfa3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove feature_importances from results\n",
    "results_visualized = {model: {metric: values for metric, values in metrics.items() if metric != 'feature_importances'} for model, metrics in results.items()}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14e14fe1ec27f089"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_visualize_results(results_visualized)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "619f69154e153895"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save feature importances with folder structure as keys\n",
    "import os\n",
    "import json\n",
    "dataset_name = \"cvd2WOBCA\"\n",
    "save_dir = \"/home/dmitrii/GitHub/ukbb_risk_assessment/analysisNumericFeatures/resources/feature_importances/permutation_importances\"\n",
    "for model in results:\n",
    "    for split in results[model]['feature_importances']:\n",
    "        for i, fi in enumerate(results[model]['feature_importances'][split]):\n",
    "            if not os.path.exists(f\"{save_dir}/{dataset_name}/{model}/{split}/\"):\n",
    "                os.makedirs(f\"{save_dir}/{dataset_name}/{model}/{split}/\")\n",
    "            fi.to_csv(f\"{save_dir}/{dataset_name}/{model}/{split}/feature_importances_{ca.RANDOM_SET_SEED[i]}.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a807dfa3887cc81"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results['XGB']['feature_importances']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57e710b1ef3580e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = ca.data[ca.data['split'] == 'train'].drop(columns=['split', 'eid', 'event', 'time_to_event']).copy()\n",
    "train_data['label'] = ca.data[ca.data['split'] == 'train']['event'].copy()\n",
    "test_data = ca.data[ca.data['split'] == 'test'].drop(columns=['split', 'eid', 'event', 'time_to_event']).copy()\n",
    "test_data['label'] = ca.data[ca.data['split'] == 'test']['event'].copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "265660c889f45083"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = best_model_predictor[0]._trainer.load_model(\"XGBoost\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38b7177e4dc65559"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# take only column from model.features\n",
    "train_data = train_data[model.features + ['label']]\n",
    "test_data = test_data[model.features + ['label']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "361d82ffa0eedfef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = best_model_predictor[0]._trainer.load_model(\"XGBoost\")\n",
    "len(model.model.feature_importances_), len(model.features), len(train_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d59eb2693bf6ee52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_feature_importances = []\n",
    "for predictor in best_model_predictor:\n",
    "    model = predictor._trainer.load_model(\"XGBoost\")\n",
    "    feature_importances = model.model.feature_importances_\n",
    "    feature_names = model.features\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importances\n",
    "    })\n",
    "    all_feature_importances.append(feature_importances)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98af84c0ee72a91c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_metrics = []\n",
    "seeds = [1514, 0, 42, 867228, 29847]\n",
    "for i, predictor in enumerate(best_model_predictor):\n",
    "    model = predictor._trainer.load_model(\"XGBoost\")\n",
    "    model.model.set_params(random_state=seeds[i], subsample=0.95, colsample_by_tree=0.9)\n",
    "    model.model.fit(train_data.drop(columns=['label']), train_data['label'])\n",
    "    y_pred = model.model.predict(test_data.drop(columns=['label']))\n",
    "    y_proba = model.model.predict_proba(test_data.drop(columns=['label']))\n",
    "    y_proba = y_proba[:, 1]\n",
    "    y_labels = test_data['label']\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_labels, y_pred),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_labels, y_pred),\n",
    "        \"f1\": f1_score(y_labels, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_labels, y_proba),\n",
    "    }\n",
    "    all_metrics.append(metrics)\n",
    "print(\"Mean metrics across seeds:\")\n",
    "print(\"Balanced Accuracy: \", np.mean([x['balanced_accuracy'] for x in all_metrics]), np.std([x['balanced_accuracy'] for x in all_metrics]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97ca4bd5bf6daeed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# import xgb\n",
    "from xgboost import XGBClassifier\n",
    "rf = RandomForestClassifier(random_state=1514, max_leaf_nodes=15000, n_estimators=300)\n",
    "\n",
    "# Assuming 'predictor' is your AutoGluon predictor and 'data' is your original dataset\n",
    "y = train_data['label']\n",
    "X = train_data.drop(columns=['label'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6684f22c63fdc1f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf.fit(X, y)\n",
    "y_pred = rf.predict(test_data.drop(columns=['label']))\n",
    "y_proba = rf.predict_proba(test_data.drop(columns=['label']))\n",
    "y_proba = y_proba[:, 1]\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(test_data['label'], y_pred),\n",
    "    \"balanced_accuracy\": balanced_accuracy_score(test_data['label'], y_pred),\n",
    "    \"f1\": f1_score(test_data['label'], y_pred),\n",
    "    \"roc_auc\": roc_auc_score(test_data['label'], y_proba),\n",
    "}\n",
    "metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c551c2a2630ef142"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "feature_names = rf.feature_names_in_\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eda391d9e12b0f3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Assuming 'train_data' and 'test_data' are your dataframes\n",
    "y_train = train_data['label']\n",
    "X_train = train_data.drop(columns=['label'])\n",
    "y_test = test_data['label']\n",
    "X_test = test_data.drop(columns=['label'])\n",
    "\n",
    "# List of seeds\n",
    "seeds = [1514, 0, 42, 867228, 29847]\n",
    "\n",
    "# To store metrics and feature importances\n",
    "all_metrics = []\n",
    "all_feature_importances = []\n",
    "\n",
    "for seed in seeds:\n",
    "    # Initialize RandomForest with current seed\n",
    "    rf = RandomForestClassifier(random_state=seed, max_leaf_nodes=15000, n_estimators=300)\n",
    "    #rf = XGBClassifier(random_state=seed, subsample=0.95, colsample_by_tree=0.95, booster='gbtree', objective='binary:logistic', base_score=5E-1)\n",
    "    \n",
    "    # Fit the model\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        \"seed\": seed,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "        \"f1\": f1_score(y_test, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_proba)\n",
    "    }\n",
    "    all_metrics.append(metrics)\n",
    "    \n",
    "    # Compute feature importances\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'feature': rf.feature_names_in_,\n",
    "        'importance': rf.feature_importances_,\n",
    "        'seed': seed\n",
    "    })\n",
    "    all_feature_importances.append(feature_importances)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8214b2c9fea9ae26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_average_feature_importance_boxplot(all_feature_importances, category_dict, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plots a boxplot for average feature importances by category, showing all categories, \n",
    "    even those without any features, but leaving them empty.\n",
    "\n",
    "    Parameters:\n",
    "    all_feature_importances (list): List of DataFrames, each containing feature importances for a seed \n",
    "                                    with columns 'feature', 'importance', and 'seed'.\n",
    "    category_dict (dict): Dictionary where keys are category names and values are lists of features.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the boxplot.\n",
    "    \"\"\"\n",
    "    # Concatenate all DataFrames in the list to form a single DataFrame\n",
    "    combined_feature_importances_df = pd.concat(all_feature_importances, ignore_index=True)\n",
    "    \n",
    "    # Calculate average importance for each feature across all seeds\n",
    "    avg_feature_importances_df = combined_feature_importances_df.groupby('feature')['importance'].mean().reset_index()\n",
    "    \n",
    "    # Prepare the data for the boxplot\n",
    "    plot_data = []\n",
    "\n",
    "    for category, features in category_dict.items():\n",
    "        # Filter for the relevant features in the current category based on averaged importances\n",
    "        category_data = avg_feature_importances_df[avg_feature_importances_df['feature'].isin(features)]\n",
    "        if not category_data.empty:\n",
    "            # Assign category and append to plot_data list\n",
    "            category_data = category_data.assign(Category=category)  # Add 'Category' column\n",
    "        else:\n",
    "            # If no data for this category, create a placeholder with NaN importance\n",
    "            placeholder_data = pd.DataFrame({\n",
    "                'feature': [np.nan],  # NaN feature to indicate no data\n",
    "                'importance': [np.nan],  # NaN importance to indicate no data\n",
    "                'Category': [category]  # Add the category name\n",
    "            })\n",
    "            plot_data.append(placeholder_data)\n",
    "        \n",
    "        plot_data.append(category_data)\n",
    "    \n",
    "    # Combine all data into a single DataFrame\n",
    "    combined_plot_data = pd.concat(plot_data, ignore_index=True)\n",
    "\n",
    "    # Plotting the boxplot using seaborn\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='Category', y='importance', data=combined_plot_data, palette='Set3', showmeans=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Average Importance')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_average_feature_importance_boxplot(all_feature_importances, features_by_category, title=\"CKD Feature Importances\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1b8fdb9714519f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#mean and std of metris\n",
    "mean, std = np.mean([x['balanced_accuracy'] for x in all_metrics]), np.std([x['balanced_accuracy'] for x in all_metrics])\n",
    "print(f\"Mean Balanced Accuracy: {mean:.3f} ± {std:.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcb2c7dd33c7be39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save all_feature_importances\n",
    "import pandas as pd\n",
    "all_feature_importances_df = pd.concat(all_feature_importances, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4432bf467ca6c624"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_feature_importances_df.to_csv(\"/home/dmitrii/GitHub/ukbb_risk_assessment/analysisNumericFeatures/resources/feature_importances/ckd_feature_importances.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93d3c71b9cc0e7fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_feature_importance_boxplot(all_feature_importances, category_dict, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plots a boxplot for feature importances by category, showing all categories,\n",
    "    including data from multiple seeds.\n",
    "\n",
    "    Parameters:\n",
    "    all_feature_importances (list): List of DataFrames, each containing feature importances for a seed \n",
    "                                    with columns 'feature', 'importance', and 'seed'.\n",
    "    category_dict (dict): Dictionary where keys are category names and values are lists of features.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the boxplot.\n",
    "    \"\"\"\n",
    "    # Concatenate all DataFrames in the list to form a single DataFrame\n",
    "    combined_feature_importances_df = pd.concat(all_feature_importances, ignore_index=True)\n",
    "    \n",
    "    # Prepare the data for the boxplot\n",
    "    plot_data = []\n",
    "\n",
    "    for category, features in category_dict.items():\n",
    "        # Filter for the relevant features in the current category across all seeds\n",
    "        category_data = combined_feature_importances_df[combined_feature_importances_df['feature'].isin(features)]\n",
    "        if not category_data.empty:\n",
    "            # Append category and importance values to the plot_data list\n",
    "            category_data = category_data.assign(Category=category)  # Add 'Category' column\n",
    "            plot_data.append(category_data)\n",
    "    \n",
    "    # Combine all data into a single DataFrame\n",
    "    combined_plot_data = pd.concat(plot_data, ignore_index=True)\n",
    "\n",
    "    # Plotting the boxplot using seaborn\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='Category', y='importance', data=combined_plot_data, palette='Set3', showmeans=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importance_boxplot(all_feature_importances, features_by_category, title=\"Pancreas Feature Importances\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fca5834626b57b39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_average_feature_importance_boxplot(all_feature_importances, category_dict, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plots a boxplot for average feature importances by category, showing all categories.\n",
    "\n",
    "    Parameters:\n",
    "    all_feature_importances (list): List of DataFrames, each containing feature importances for a seed \n",
    "                                    with columns 'feature', 'importance', and 'seed'.\n",
    "    category_dict (dict): Dictionary where keys are category names and values are lists of features.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the boxplot.\n",
    "    \"\"\"\n",
    "    # Concatenate all DataFrames in the list to form a single DataFrame\n",
    "    combined_feature_importances_df = pd.concat(all_feature_importances, ignore_index=True)\n",
    "    \n",
    "    # Calculate average importance for each feature across all seeds\n",
    "    avg_feature_importances_df = combined_feature_importances_df.groupby('feature')['importance'].mean().reset_index()\n",
    "    \n",
    "    # Prepare the data for the boxplot\n",
    "    plot_data = []\n",
    "\n",
    "    for category, features in category_dict.items():\n",
    "        # Filter for the relevant features in the current category based on averaged importances\n",
    "        category_data = avg_feature_importances_df[avg_feature_importances_df['feature'].isin(features)]\n",
    "        if not category_data.empty:\n",
    "            # Assign category and append to plot_data list\n",
    "            category_data = category_data.assign(Category=category)  # Add 'Category' column\n",
    "            plot_data.append(category_data)\n",
    "    \n",
    "    # Combine all data into a single DataFrame\n",
    "    combined_plot_data = pd.concat(plot_data, ignore_index=True)\n",
    "\n",
    "    # Plotting the boxplot using seaborn\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='Category', y='importance', data=combined_plot_data, palette='Set3', showmeans=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Average Importance')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "plot_average_feature_importance_boxplot(all_feature_importances, features_by_category, title=\"CVD2 w/o BCA Feature Importances\")\n",
    "# Example usage:\n",
    "# Assuming 'all_feature_importances' is a list of DataFrames containing feature importances from all seeds\n",
    "# with columns: 'feature', 'importance', and 'seed'.\n",
    "\n",
    "# Example category_dict:\n",
    "# category_dict = {\n",
    "#     'Category1': ['feature1', 'feature2'],\n",
    "#     'Category2': ['feature3', 'feature4'],\n",
    "#     # ... other categories\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a278cbb156dea9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_average_feature_importance_boxplot(all_feature_importances, category_dict, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plots a boxplot for average feature importances by category, showing all categories, \n",
    "    even those without any features, but leaving them empty.\n",
    "\n",
    "    Parameters:\n",
    "    all_feature_importances (list): List of DataFrames, each containing feature importances for a seed \n",
    "                                    with columns 'feature', 'importance', and 'seed'.\n",
    "    category_dict (dict): Dictionary where keys are category names and values are lists of features.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the boxplot.\n",
    "    \"\"\"\n",
    "    # Concatenate all DataFrames in the list to form a single DataFrame\n",
    "    combined_feature_importances_df = pd.concat(all_feature_importances, ignore_index=True)\n",
    "    \n",
    "    # Calculate average importance for each feature across all seeds\n",
    "    avg_feature_importances_df = combined_feature_importances_df.groupby('feature')['importance'].mean().reset_index()\n",
    "    \n",
    "    # Prepare the data for the boxplot\n",
    "    plot_data = []\n",
    "\n",
    "    for category, features in category_dict.items():\n",
    "        # Filter for the relevant features in the current category based on averaged importances\n",
    "        category_data = avg_feature_importances_df[avg_feature_importances_df['feature'].isin(features)]\n",
    "        if not category_data.empty:\n",
    "            # Assign category and append to plot_data list\n",
    "            category_data = category_data.assign(Category=category)  # Add 'Category' column\n",
    "        else:\n",
    "            # If no data for this category, create a placeholder with NaN importance\n",
    "            placeholder_data = pd.DataFrame({\n",
    "                'feature': [np.nan],  # NaN feature to indicate no data\n",
    "                'importance': [np.nan],  # NaN importance to indicate no data\n",
    "                'Category': [category]  # Add the category name\n",
    "            })\n",
    "            plot_data.append(placeholder_data)\n",
    "        \n",
    "        plot_data.append(category_data)\n",
    "    \n",
    "    # Combine all data into a single DataFrame\n",
    "    combined_plot_data = pd.concat(plot_data, ignore_index=True)\n",
    "\n",
    "    # Plotting the boxplot using seaborn\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='Category', y='importance', data=combined_plot_data, palette='Set3', showmeans=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Average Importance')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_average_feature_importance_boxplot(all_feature_importances, features_by_category, title=\"Pancreas Feature Importances\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f265f48b83437364"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read json\n",
    "import json\n",
    "with open('./resources/feature_importances/features_by_category.json') as f:\n",
    "    features_by_category = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36107e4724b49236"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e5699708ae00b603"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_feature_importance_boxplot(feature_importances, features_by_category, title=\"Pancreas Feature Importances\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1b20400f20a548"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_feature_importance_manhattan(df, category_dict):\n",
    "    \"\"\"\n",
    "    Plots a Manhattan plot for feature importances by category.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with columns 'feature' and 'importance'.\n",
    "    category_dict (dict): Dictionary where keys are category names and values are lists of features.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the Manhattan plot.\n",
    "    \"\"\"\n",
    "    # Create a reverse lookup for category from feature\n",
    "    feature_to_category = {feature: category for category, features in category_dict.items() for feature in features}\n",
    "    \n",
    "    # Map each feature to its category\n",
    "    df['category'] = df['feature'].map(feature_to_category)\n",
    "    \n",
    "    # Assign a numeric value to each category\n",
    "    category_mapping = {category: idx for idx, category in enumerate(category_dict.keys())}\n",
    "    df['category_id'] = df['category'].map(category_mapping)\n",
    "\n",
    "    # Plotting the Manhattan plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(df['category_id'], df['importance'], c='blue', alpha=0.6)\n",
    "    \n",
    "    # Add horizontal lines for significance thresholds if necessary\n",
    "    # plt.axhline(y=0.1, color='r', linestyle='--', label='Threshold')\n",
    "\n",
    "    # Customize x-axis with category labels\n",
    "    plt.xticks(ticks=list(category_mapping.values()), labels=list(category_mapping.keys()), rotation=45)\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Feature Importance')\n",
    "    plt.title('Feature Importance Manhattan Plot by Category')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importance_manhattan(feature_importances, features_by_category)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a60558457314f3c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def plot_feature_importance_manhattan(all_feature_importances, category_dict):\n",
    "    \"\"\"\n",
    "    Plots a Manhattan plot for feature importances by category across all seeds.\n",
    "\n",
    "    Parameters:\n",
    "    all_feature_importances (list): List of DataFrames, each containing feature importances for a seed \n",
    "                                    with columns 'feature', 'importance', and 'seed'.\n",
    "    category_dict (dict): Dictionary where keys are category names and values are lists of features.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the Manhattan plot.\n",
    "    \"\"\"\n",
    "    # Concatenate all DataFrames in the list to form a single DataFrame\n",
    "    combined_feature_importances_df = pd.concat(all_feature_importances, ignore_index=True)\n",
    "    \n",
    "    # Create a reverse lookup for category from feature\n",
    "    feature_to_category = {feature: category for category, features in category_dict.items() for feature in features}\n",
    "    \n",
    "    # Map each feature to its category\n",
    "    combined_feature_importances_df['category'] = combined_feature_importances_df['feature'].map(feature_to_category)\n",
    "    \n",
    "    # Assign a numeric value to each category\n",
    "    category_mapping = {category: idx for idx, category in enumerate(category_dict.keys())}\n",
    "    combined_feature_importances_df['category_id'] = combined_feature_importances_df['category'].map(category_mapping)\n",
    "\n",
    "    # Plotting the Manhattan plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(combined_feature_importances_df['category_id'], \n",
    "                combined_feature_importances_df['importance'], \n",
    "                c='blue', alpha=0.6)\n",
    "    \n",
    "    # Customize x-axis with category labels\n",
    "    plt.xticks(ticks=list(category_mapping.values()), labels=list(category_mapping.keys()), rotation=45)\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Feature Importance')\n",
    "    plt.title('Feature Importance Manhattan Plot by Category Across All Seeds')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "plot_feature_importance_manhattan(all_feature_importances, features_by_category)\n",
    "# Example usage:\n",
    "# Assuming 'all_feature_importances' is a list of DataFrames containing feature importances from all seeds\n",
    "# with columns: 'feature', 'importance', and 'seed'.\n",
    "\n",
    "# Example category_dict:\n",
    "# category_dict = {\n",
    "#     'Category1': ['feature1', 'feature2'],\n",
    "#     'Category2': ['feature3', 'feature4'],\n",
    "#     # ... other categories\n",
    "# }\n",
    "# plot_feature_importance_manhattan(all_feature_importances, category_dict)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c7b2f302c12e6d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def plot_average_feature_importance_manhattan(all_feature_importances, category_dict):\n",
    "    \"\"\"\n",
    "    Plots a Manhattan plot for average feature importances by category across seeds.\n",
    "\n",
    "    Parameters:\n",
    "    all_feature_importances (list): List of DataFrames, each containing feature importances for a seed \n",
    "                                    with columns 'feature', 'importance', and 'seed'.\n",
    "    category_dict (dict): Dictionary where keys are category names and values are lists of features.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the Manhattan plot.\n",
    "    \"\"\"\n",
    "    # Concatenate all DataFrames in the list to form a single DataFrame\n",
    "    combined_feature_importances_df = pd.concat(all_feature_importances, ignore_index=True)\n",
    "    \n",
    "    # Calculate the average importance for each feature across all seeds\n",
    "    avg_feature_importances_df = combined_feature_importances_df.groupby('feature')['importance'].mean().reset_index()\n",
    "    \n",
    "    # Create a reverse lookup for category from feature\n",
    "    feature_to_category = {feature: category for category, features in category_dict.items() for feature in features}\n",
    "    \n",
    "    # Map each feature to its category\n",
    "    avg_feature_importances_df['category'] = avg_feature_importances_df['feature'].map(feature_to_category)\n",
    "    \n",
    "    # Assign a numeric value to each category\n",
    "    category_mapping = {category: idx for idx, category in enumerate(category_dict.keys())}\n",
    "    avg_feature_importances_df['category_id'] = avg_feature_importances_df['category'].map(category_mapping)\n",
    "\n",
    "    # Plotting the Manhattan plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(avg_feature_importances_df['category_id'], \n",
    "                avg_feature_importances_df['importance'], \n",
    "                c='blue', alpha=0.6)\n",
    "    \n",
    "    # Customize x-axis with category labels\n",
    "    plt.xticks(ticks=list(category_mapping.values()), labels=list(category_mapping.keys()), rotation=45)\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Average Feature Importance')\n",
    "    plt.title('Average Feature Importance Manhattan Plot by Category Across Seeds')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "plot_average_feature_importance_manhattan(all_feature_importances, features_by_category)\n",
    "# Example usage:\n",
    "# Assuming 'all_feature_importances' is a list of DataFrames containing feature importances from all seeds\n",
    "# with columns: 'feature', 'importance', and 'seed'.\n",
    "\n",
    "# Example category_dict:\n",
    "# category_dict = {\n",
    "#     'Category1': ['feature1', 'feature2'],\n",
    "#     'Category2': ['feature3', 'feature4'],\n",
    "#     # ... other categories\n",
    "# }\n",
    "# plot_average_feature_importance_manhattan(all_feature_importances, category_dict)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8647d38e8060584"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importances = model.model.feature_importances_\n",
    "feature_names = model.feature_metadata.get_features()\n",
    "feature_importances = dict(zip(feature_names, importances))\n",
    "print(feature_importances)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cf760bd87c9e928"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read json\n",
    "import json\n",
    "with open('./resources/feature_importances/features_by_category.json') as f:\n",
    "    features_by_category = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "499d33e8df96dd4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# bca +/ cardiac + questionnaire\n",
    "_visualize_results(results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92fef7db615560f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# bca +/ cardiac + questionnaire\n",
    "_visualize_results(results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2ec48388c87a85e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = ca.data[ca.data['split'] == 'train'].drop(columns=['split', 'eid', 'event', 'time_to_event']).copy()\n",
    "train_data['label'] = ca.data[ca.data['split'] == 'train']['event'].copy()\n",
    "test_data = ca.data[ca.data['split'] == 'test'].drop(columns=['split', 'eid', 'event', 'time_to_event']).copy()\n",
    "test_data['label'] = ca.data[ca.data['split'] == 'test']['event'].copy()\n",
    "val_data = ca.data[ca.data['split'] == 'val'].drop(columns=['split', 'eid', 'event', 'time_to_event']).copy()\n",
    "val_data['label'] = ca.data[ca.data['split'] == 'val']['event'].copy()\n",
    "test_val_data = pd.concat([test_data, val_data])\n",
    "model = 'RF'\n",
    "seed = SEEDS[0]\n",
    "\n",
    "predictor = ag.TabularPredictor(label='label', eval_metric='balanced_accuracy', path=f'./autogluon/model_{model}_seed_{seed}', verbosity=2, problem_type='binary')\n",
    "hyperparameters = {\n",
    "    model: {\n",
    "        model: {\n",
    "            'random_state': seed,  # Use your seed here\n",
    "            #'subsample': 0.98,\n",
    "            #'colsample_bytree': 0.98,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    tuning_data=val_data,  # Set validation data for hyperparameter tuning\n",
    "    hyperparameters=hyperparameters[model],\n",
    "    time_limit=3600,   # Time limit per seed (10 minutes)\n",
    "    num_bag_folds=0,  # No bagging\n",
    "    num_stack_levels=0,  # No stacking\n",
    "    presets='best_quality',  # Best quality preset\n",
    ")\n",
    "\n",
    "y_pred = predictor.predict(test_data)\n",
    "y_proba = predictor.predict_proba(test_data)\n",
    "y_proba = y_proba.to_numpy()[:, 1]\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(test_data['label'], y_pred),\n",
    "    \"balanced_accuracy\": balanced_accuracy_score(test_data['label'], y_pred),\n",
    "    \"f1\": f1_score(test_data['label'], y_pred),\n",
    "    \"roc_auc\": roc_auc_score(test_data['label'], y_proba),\n",
    "}\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "fi = predictor.feature_importance(data=test_val_data, num_shuffle_sets=5)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c95880450cf223dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(fi[fi['importance'] >= 0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e596997d29f679e8"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "94aef9f445afdbf8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fi[fi['p_value'] < 0.05]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5eb5640802817c09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#save the feature importance\n",
    "fi.to_csv(\"/home/dmitrii/GitHub/ukbb_risk_assessment/analysisNumericFeatures/resources/cvdWOBCA_feature_importances.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "347acfccca2f2484"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fi[fi['p_value'] < 0.05]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ba930d4727cce28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#save the feature importance\n",
    "fi.to_csv(\"/home/dmitrii/GitHub/ukbb_risk_assessment/analysisNumericFeatures/resources/cvd2All_feature_importances_+val.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b1f8560c15bcbbc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# bca / cardiac\n",
    "_visualize_results(results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6d838883972bd65"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# questionnaire\n",
    "_visualize_results(results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f8241c53e1ad0c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import autogluon.tabular as ag\n",
    "from autogluon.common import space\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "def train_and_evaluate(ca):\n",
    "    seeds = ca.RANDOM_SET_SEED[:5]\n",
    "    \n",
    "    # Prepare the training and test datasets\n",
    "    train_data = ca.data[ca.data['split'] == 'train'].drop(columns=['split', 'eid', 'event', 'time_to_event']).copy()\n",
    "    train_data['label'] = ca.data[ca.data['split'] == 'train']['event'].copy()\n",
    "    test_data = ca.data[ca.data['split'] == 'test'].drop(columns=['split', 'eid', 'event', 'time_to_event']).copy()\n",
    "    test_data['label'] = ca.data[ca.data['split'] == 'test']['event'].copy()\n",
    "    val_data = ca.data[ca.data['split'] == 'val'].drop(columns=['split', 'eid', 'event', 'time_to_event']).copy()\n",
    "    val_data['label'] = ca.data[ca.data['split'] == 'val']['event'].copy()\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    models_to_train = ['RF', 'XGB', 'NN_TORCH']\n",
    "\n",
    "    for model in models_to_train:\n",
    "        results[model] = {'accuracy': [], 'balanced_accuracy': [], 'f1': [], 'roc_auc': []}\n",
    "        for seed in seeds:\n",
    "\n",
    "            predictor = ag.TabularPredictor(label='label', eval_metric='f1', path=f'./autogluon/model_{model}_seed_{seed}', verbosity=2, problem_type='binary')\n",
    "\n",
    "            hyperparameters = {\n",
    "                'RF': {\n",
    "                    'RF': {\n",
    "                        'n_estimators': space.Int(100, 1000),\n",
    "                        'max_depth': space.Int(5, 50),\n",
    "                        'min_samples_split': space.Int(2, 10),\n",
    "                        'min_samples_leaf': space.Int(1, 4),\n",
    "                        'random_state': space.Int(seed, seed),\n",
    "                    }\n",
    "                },  \n",
    "                'XGB': {\n",
    "                    'XGB': {\n",
    "                        'n_estimators': space.Int(100, 1000),\n",
    "                        'learning_rate': space.Real(0.01, 0.3),\n",
    "                        'max_depth': space.Int(3, 10),\n",
    "                        'subsample': space.Real(0.5, 1.0),  # Tuning subsample\n",
    "                        'colsample_bytree': space.Real(0.5, 1.0),  # Tuning colsample_bytree\n",
    "                        'random_state': seed,\n",
    "                    }\n",
    "                },\n",
    "                'NN_TORCH': {\n",
    "                    'NN_TORCH': {\n",
    "                        \"num_layers\": space.Int(1, 3),\n",
    "                        \"hidden_size\": space.Int(64, 512),\n",
    "                        \"dropout_prob\": space.Real(0.0, 0.5),\n",
    "                        \"learning_rate\": space.Real(0.0001, 0.01),\n",
    "                        \"seed_value\": seed,\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            predictor.fit(\n",
    "                train_data=train_data,\n",
    "                tuning_data=val_data,  # Set validation data for hyperparameter tuning\n",
    "                hyperparameters=hyperparameters[model],\n",
    "                time_limit=600,   # Time limit per seed (10 minutes)\n",
    "                num_bag_folds=0,  # No bagging\n",
    "                num_stack_levels=0,  # No stacking\n",
    "                presets='best_quality',  # Best quality preset\n",
    "            )\n",
    "            \n",
    "            y_pred = predictor.predict(test_data)\n",
    "            y_proba = predictor.predict_proba(test_data)\n",
    "            y_proba = y_proba.to_numpy()[:, 1]\n",
    "            metrics = {\n",
    "                \"accuracy\": accuracy_score(test_data['label'], y_pred),\n",
    "                \"balanced_accuracy\": balanced_accuracy_score(test_data['label'], y_pred),\n",
    "                \"f1\": f1_score(test_data['label'], y_pred),\n",
    "                \"roc_auc\": roc_auc_score(test_data['label'], y_proba),\n",
    "            }\n",
    "    \n",
    "            # Store the metrics for this model and seed\n",
    "            for metric in metrics:\n",
    "                results[model][metric].append(metrics[metric])\n",
    "        \n",
    "    # Calculate mean and standard deviation across seeds for each model\n",
    "    results_combined = {}\n",
    "    for model_name in results:\n",
    "        results_combined[model_name] = {}\n",
    "        for metric in results[model_name]:\n",
    "            results_combined[model_name][metric] = {\n",
    "                \"mean\": np.mean(results[model_name][metric]),\n",
    "                \"std\": np.std(results[model_name][metric])\n",
    "            }\n",
    "    \n",
    "    return results_combined, predictor\n",
    "\n",
    "\n",
    "results, predictor = train_and_evaluate(ca)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef6a96e6c215a783"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
